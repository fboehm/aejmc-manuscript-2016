---
title: Data Analysis with Topic Models for Communications Researchers
output: 
  pdf_document:
    keep_tex: true
    toc: false
    number_sections: true
    includes:
      in_header: header.tex
      before_body: doc_prefix.tex
      after_body: doc_suffix.tex
fontsize: 12pt
geometry: margin=1in
bibliography: twitter.bib
csl: apa.csl
---

\listoftodos


# Abstract

We present a non-technical introduction to data analysis with topic models for communications researchers. We motivate the discussion with a research question from social media communications research. We then discuss statistical aspects of topic models as we illustrate these methods with data from Twitter. We complement our discussion with computer code (in the R computing language) that implements these methods. We close with thoughts about the future value of topic modeling to communications researchers.
\todo[inline]{Do I want to emphasize data analysis more? I think so}


# Motivation

\todo[color=pink]{Can we write a scenario like that of Blei's 2012 article?}

We are in the big data era. Social media inundates us with status updates and tweets, while bloggers share their views on current events. These new media interact with more established media, such as print news media, television, and radio. What do they have in common? One answer is that they all can be viewed as data sources in which words - whether written or spoken, tweeted or blogged - are the data. 

Think about how we currently browse media. Let's suppose that we want to read about mass shootings. We might search for the key words "mass" and "shooting". Doing so, we will find some articles that deal with mass shootings, but other results may deal with other types of "shootings", such as film shooting or television shooting. Even if we specify that the two-word phrase "mass shooting" must appear in our results, we still may find some articles that merely mention mass shootings without focusing on one or more mass shootings. 

@blei2012probabilistic envisions an alternative search strategy in which we search for articles that are *about* "mass shootings". Some of the resulting articles would have the phrase "mass shooting", but containing that two-word phrase is not required; the sole requirement is that the article focus on one or more mass shootings. That is, we'd like to see all of the articles that have the theme, or "topic", mass shooting. Topic modeling is one method that may ultimately enable us to do the theme-based browsing that @blei2012probabilistic suggests. 

"Topic modeling" refers to a collection of statistical and machine learning methods that have the goal of discovering latent topics in a collection, or "corpus", of texts. The tremendous rise in computing speed and memory capacity, coupled with the increasing avaialability of digitized texts, has enabled researchers working at the interface of quantitative methods and social sciences to treat written texts as data. While data analysis of documents is still in its infancy, scientists nevertheless have made great progress towards computational dissection and interpretation of texts. Among the most foundational contributions is the development of probabilistic topic models. We detail below, with limited use of statistical terminology, how these methods work and why they may be useful in communications research. We illustrate topic modeling methods in the analysis of all New York Times articles from three days in March 2016. We also provide an appendix with computer code (in the R programming language) that implements these methods.

```{r setup, include=FALSE}
library(knitr)
opts_chunk$set(echo=FALSE) # hide source code in the document
```

```{r chunka}
# chunk a
1+1
```




```{r chunkb}
# chunk b
2+2
```

blah

```{r chunkc}
# chunk c
rnorm(10)
```




# What types of data analysis problems have others addressed with topic modeling?

- can we find several (3 or 4) motivating examples?
1. genetics & ancestral populations -- STRUCTURE paper 2000
2. political science 2010 paper... on what??
3. what did John Dawson do?

# What types of data? 

1. streaming... what makes this - topic modeling with streaming data - interesting
2. hierarchical... how?
3. Victorian Eyes









# Box's Loop & Data analysis

\todo[inline, color=pink]{Need one or two figures here}

\missingfigure{Box's loop from 1976? Blei 2014?}

The perspective that guides our data analysis is based on ideas of the University of Wisconsin-Madison statistician George Box and coworkers. @blei2014build extends the ideas of Box and colleagues to the specific case of iterative refinement of topic models. Box (CITATION) articulated a process of scientific inquiry and statistical collaboration in which scientists put forth a hypothesis about the natural world, and, with assistance from statisticians, design experiments to test the scientific hypothesis. After statistical analysis of the experimental data, the scientific hypothesis is refined, which leads to design and implementation of another experiment, and the iterative process between scientific hypothesis and experiment continues. Box also suggested (CITATION) that a statistician, working in collaboration with scientists, might use scientific questions as motivation to develop new statistical methods in experimental design and data analysis. In this sense, there is a second iterative loop by which a statistical researcher develops novel methods because of their immediate need to answer a scientific research question. @blei2014build adapts these iterative processes to the case of latent variable models, such as LDA and related models. He argues that we view the use of a topic model for a specific data analysis task as an iterative procedure in which one proposes a simple topic model for the data analysis, fits the model, interprets the results, and then, if needed, refines the topic model with the goal of achieving data analysis results that are more consistent with the research goals. 




# Latent Dirichlet Allocation

@blei2003latent introduced a (generative) statistical model called "latent dirichlet allocation" (LDA) in 2003. Although others had described similar statistical models [@pritchard2000inference], @blei2003latent first applied the statistical model to text analysis. Researchers in a wide range of disciplines - including genetics, linguistics, psychology, political science, and others - have enthusiastically adopted LDA and related methods. 



## What is the intuition behind the model?

As @blei2012probabilistic writes, the key to understanding LDA is to recognize that a given document - be it a research article, a novel, or a blog post - exhibits multiple topics. Each topic, in turn, is, in a technical sense, a distribution over words. For example, a topic related to evolution may heavily weight the words "evolution", "evolutionary", "biology", "phylogenetic", and "species". In a given collection of documents, which we term a "corpus" of documents, we assume that relatively few topics - on the order of 10 to 50 for most analyses - are present. 

## In what sense is the model 'generative'?

We say that LDA is a generative model because we specify a joint probability distribution that allows generation of observed samples. In a more precise manner, we specify a distribution over topics (again, where topics are themselves distributions over words) that is shared by the corpus. Each document can be viewed as a draw from this distribution. The observed topic (distribution over words) tells us how the words are distributed. 


# LDA with statistical terminology

We can also describe LDA with more formal statistical terminology. We let $\beta_1, \beta_2, ..., \beta_K$ be the $K$ topics, where each $\beta_k$ is a distribution over the vocabulary. Topic weights (or proportions) we denote by $\theta_d$ for the $d^{th}$ document. We let $\theta_{d,k}$ be the topic proportion for topic $k$ in document $d$. Topic assignments for the $d^{th}$ document are $z_d$, where $z_{d,n}$ is the topic assignment for the $n^{th}$ word in the $d^{th}$ document. Observed words for the $d^{th}$ document are $w_d$, where $w_{d, n}$ is the $n^{th}$ word for the $d^{th}$ document.

We then use the above notation to specify the joint distribution for all variables in the model:

$$p(\beta_{1:K}, \theta_{1:D}, z_{1:D}, w_{1:D}) = \prod_{i = 1}^Kp(\beta_i)\prod_{d = 1}^Dp(\theta_d)\left( \prod_{n = 1}^N p(z_{d,n}|\theta_d)p(w_{d,n}|\beta_{1:K}, z_{d,n})\right)$$

The vertical bars in the last expressions denote conditional probabilities. Note that the topic assignments $z_{d,n}$ depend on the document's topic proportions. Whatismore, the observed word $w_{d,n}$ has a distribution that depends on both the entire collection of topics, $\beta_{1:K}$, and the topic, $z_{d,n}$, assigned to that word.

# Example of LDA with print media

An example may help to illustrate our point. 

- which example to use here? NY Times

We analyzed 


@blei2007correlated fitted a 100-topic model to 17,000 research articles from the journal Science. They found that a 1996 article "Seeking Life's Bare (Genetic) Necessities" [@pennisi1996seeking] exhibited topics related to "evolution", "genetics", "disease", and "computers".
**Would it be more sensible to use RT's Super Bowl results here?**






## What is the model?

LDA models have a hiearchical structure in which words make up documents, and a collection of documents is a corpus. The corpus is assumed to have (unobserved) topics, or themes. The purposes of LDA, then, are to discover the unobserved topics from the texts and to characterize documents by the topics that they contain.

We distinguish generative models from discriminative models. A generative model, such as LDA, is one in which we specify a joint probability distribution for all variables (including those that are unobserved) and, thus, enable the creation of observations. On the other hand, a discriminative model relies on a conditional distribution and doesn't permit generation of samples from the joint distribution. 





## What are its assumptions?





## What are its limitations? 

The original LDA model However, LDA's flexibility and adaptability have reduced the impact of its initial limitations. In the last decade, researchers have devised extensions of LDA, such as "dynamic LDA", that enable one to model topic evolution over time. Another extension of LDA, which is known as "correlated LDA", accounts for correlations among topics. 


# Inference in topic models

Existing strategies for fitting topic models can be divided into two classes: 1. variational Bayes methods and 2. sampling methods. Variational Bayes methods try to approximate the posterior distribution by maximizing a lower bound. In this sense, variational Bayes methods approach topic model fitting from a computer science optimization perspective. Alternatively, sampling methods, such as those based on Markov chain monte carlo (MCMC) approaches, draw samples from (an approximation to) the posterior distribution and estimate distributional parameters by their empirical sample statistics. 

Computational implementations of both classes of strategies are freely available for the R statistical computing language. We include code to use these free implementations in the appendix.  

# Interpreting results of topic modeling

Statistical inference for topic models yields estimates for topics (i.e., distributions over words), assignments of words (within documents) to topics, and weights of topics in each document. 

The user must impose meaning on the topics. For instance, a topic may put heavy weights on the words "genetics", "gene", "regulation", "DNA", "transcription", and "RNA". The data analyst needs to identify the similarities among these words - namely, that they describe concepts related to genetics and molecular biology. Fortunately, topic modeling procedures often generate topics that can be summarized in one or two words once the data analyst has inspected the most heavily weighted terms (for a given topic). 


# Visualizing topics

- LDAvis
- wordcloud

  Visualizing topic modeling results is an active area of research. We present below strategies that involve static and interactive displays. 

  Word clouds are a widely used method for presenting topic modeling results. Unfortunately, the standard approach requires a distinct word cloud for each topic. For models with more than ten topics, manually examining wordclouds becomes unwieldy. 
  For a single topic, the default method for creating a word cloud involves the identification of the most heavily weighted words in the topic. The user may choose to assign font sizes that are proportional to the weights of each word.
  One newly developed method, which is implemented in the LDAvis R package, uses a singular value decomposition of the fitted document-topic matrix to calculate principal components. Each topic is then plotted in two dimensions, where the axes represent the first two principal components. The LDAvis R package enhances this second approach by making the figures interactive with D3 javascript.
  
  
  



# Results from NY Times "Obama" Analysis

\begin{figure}
\includegraphics[width=\textwidth]{2016-03-17-obama_files/figure-latex/wordcloud-3.pdf}
\caption{Wordcloud for one topic from a 20-topic model. Larger font size corresponds to greater weight of that word in this topic.\label{fig:wc3}}
\end{figure}

We examine several wordclouds of topics derived from our analysis of 267 New York Times articles that contain the word "Obama". We notice in Figure \ref{fig:wc3} words that relate to civil rights. Words that emphasize race or sexual orientation feature prominently. It's possible that if we were to fit a model with more topics, say 50, that race and sexual orientation might occupy distinct topics.

\begin{figure}
\includegraphics[width=\textwidth]{2016-03-17-obama_files/figure-latex/wordcloud-4.pdf}
\caption{Wordcloud for one topic from a 20-topic model. Larger font size corresponds to greater weight of that word in this topic.\label{fig:wc4}}
\end{figure}

Figure \ref{fig:wc4} contains words that deal with Barack Obama's biography. 

\begin{figure}
\includegraphics[width=\textwidth]{2016-03-17-obama_files/figure-latex/wordcloud-5.pdf}
\caption{Wordcloud for one topic from a 20-topic model. Larger font size corresponds to greater weight of that word in this topic.\label{fig:wc5}}
\end{figure}

Whatismore, Figure \ref{fig:wc5} highlights the use of political terms in articles that contain the word "Obama". 

\begin{figure}
\includegraphics[width=\textwidth]{2016-03-17-obama_files/figure-latex/wordcloud-8.pdf}
\caption{Wordcloud for one topic from a 20-topic model. Larger font size corresponds to greater weight of that word in this topic.\label{fig:wc8}}
\end{figure}

International relations words make up the topic visualized in Figure \ref{fig:wc8}.


# Discussion



# Future directions



# Online resources

David Mimno, a Cornell University scholar, curates an annotated bibliography of topic modeling research[@mimno2016topic]. His bibliography is available at this url: http://mimno.infosci.cornell.edu/topics.html


# Computational implementation of LDA with R

We present below instructions and code for using LDA in the R statistical computing language [@r2015].
**Ask Dhavan about including code?** **Maybe as an appendix?**

Now we show all the code chunks:

```{r all-code, ref.label=all_labels(), echo=TRUE, eval=FALSE}

```



# References





